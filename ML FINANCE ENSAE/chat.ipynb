{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f99428d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import all the necessary libraries\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "\n",
    "# Load the environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d604e0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "groq/compound\n",
      "openai/gpt-oss-120b\n",
      "groq/compound-mini\n",
      "llama-3.1-8b-instant\n",
      "whisper-large-v3\n",
      "whisper-large-v3-turbo\n",
      "playai-tts\n",
      "meta-llama/llama-4-maverick-17b-128e-instruct\n",
      "openai/gpt-oss-safeguard-20b\n",
      "qwen/qwen3-32b\n",
      "meta-llama/llama-guard-4-12b\n",
      "meta-llama/llama-prompt-guard-2-86m\n",
      "allam-2-7b\n",
      "playai-tts-arabic\n",
      "llama-3.3-70b-versatile\n",
      "moonshotai/kimi-k2-instruct\n",
      "meta-llama/llama-prompt-guard-2-22m\n",
      "moonshotai/kimi-k2-instruct-0905\n",
      "openai/gpt-oss-20b\n",
      "meta-llama/llama-4-scout-17b-16e-instruct\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "client = OpenAI(base_url=\"https://api.groq.com/openai/v1\",)\n",
    "models = client.models.list()\n",
    "for m in models:\n",
    "    print(m.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daaf42ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ‚ÄúHello‚ÄØWorld‚Äù of AI is a tiny program that shows you can create a model, feed it data, and get a prediction back‚Äîwithout any heavy‚Äëlifting or external data.  \n",
      "Below are three classic ‚ÄúHello‚ÄØWorld‚Äù snippets in the three most common AI frameworks. Pick the one you‚Äôre comfortable with and run it; you‚Äôll see a model learn a single pattern in a handful of lines.\n",
      "\n",
      "---\n",
      "\n",
      "## 1Ô∏è‚É£‚ÄØTensorFlow / Keras ‚Äì Learn‚ÄØ\\(y = 2x + 1\\)\n",
      "\n",
      "```python\n",
      "# hello_ai_tf.py\n",
      "import tensorflow as tf\n",
      "import numpy as np\n",
      "\n",
      "# Training data:  x ‚Üí y = 2x + 1\n",
      "x = np.array([0., 1., 2., 3., 4.], dtype=np.float32)\n",
      "y = 2 * x + 1\n",
      "\n",
      "# A single‚Äëlayer linear model (y = wx + b)\n",
      "model = tf.keras.Sequential([\n",
      "    tf.keras.layers.Dense(1, input_shape=(1,))\n",
      "])\n",
      "\n",
      "model.compile(optimizer='sgd', loss='mse')\n",
      "model.fit(x, y, epochs=200, verbose=0)\n",
      "\n",
      "# Test it\n",
      "print(\"Prediction for x=10:\", model.predict([10.0])[0][0])\n",
      "# Expected ‚âà 21\n",
      "```\n",
      "\n",
      "**Why it‚Äôs ‚ÄúHello‚ÄØWorld‚Äù**  \n",
      "- One layer ‚Üí one line of code.  \n",
      "- Trains in a few milliseconds.  \n",
      "- Shows the full AI pipeline: data ‚Üí model ‚Üí training ‚Üí inference.\n",
      "\n",
      "---\n",
      "\n",
      "## 2Ô∏è‚É£‚ÄØPyTorch ‚Äì Same linear regression\n",
      "\n",
      "```python\n",
      "# hello_ai_torch.py\n",
      "import torch\n",
      "\n",
      "# Data\n",
      "x = torch.tensor([[0.], [1.], [2.], [3.], [4.]])\n",
      "y = 2 * x + 1\n",
      "\n",
      "# Simple linear model: y = wx + b\n",
      "model = torch.nn.Linear(1, 1)   # weight + bias are created automatically\n",
      "\n",
      "criterion = torch.nn.MSELoss()\n",
      "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
      "\n",
      "# Train\n",
      "for epoch in range(200):\n",
      "    optimizer.zero_grad()\n",
      "    y_pred = model(x)\n",
      "    loss = criterion(y_pred, y)\n",
      "    loss.backward()\n",
      "    optimizer.step()\n",
      "\n",
      "# Test\n",
      "with torch.no_grad():\n",
      "    print(\"Prediction for x=10:\", model(torch.tensor([[10.0]])).item())\n",
      "# Expected ‚âà 21\n",
      "```\n",
      "\n",
      "**What you see**  \n",
      "- Explicit forward‚Äëbackward loop (the ‚Äúbrain‚Äù of most AI code).  \n",
      "- Direct access to gradients, which is useful when learning how training works.\n",
      "\n",
      "---\n",
      "\n",
      "## 3Ô∏è‚É£‚ÄØScikit‚Äëlearn ‚Äì A tiny classifier\n",
      "\n",
      "If you just want a *quick* ‚ÄúAI works‚Äù demo without any deep‚Äëlearning boilerplate, a one‚Äëliner with scikit‚Äëlearn is perfect:\n",
      "\n",
      "```python\n",
      "from sklearn.datasets import load_iris\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "\n",
      "X, y = load_iris(return_X_y=True)          # classic 150‚Äësample dataset\n",
      "clf = LogisticRegression(max_iter=200).fit(X, y)\n",
      "\n",
      "print(\"Prediction for first sample:\", clf.predict([X[0]]))\n",
      "# Should match y[0] (the true class)\n",
      "```\n",
      "\n",
      "**Why this works**  \n",
      "- No manual gradient code; the library does the heavy lifting.  \n",
      "- Shows a *real* ML task (multiclass classification) in a single line.\n",
      "\n",
      "---\n",
      "\n",
      "## What Makes These ‚ÄúHello‚ÄØWorld‚Äù Programs Special?\n",
      "\n",
      "| Element | Reason |\n",
      "|--------|--------|\n",
      "| **Tiny dataset** | You can see the whole training process instantly. |\n",
      "| **One‚Äëlayer model** | No hidden complexities‚Äîjust the core math (weights & bias). |\n",
      "| **Immediate inference** | After training you can query the model right away. |\n",
      "| **Few dependencies** | All three examples run with a single `pip install` command (`tensorflow`, `torch`, or `scikit-learn`). |\n",
      "| **Conceptual coverage** | Linear regression ‚Üí classification ‚Üí gradient descent ‚Äì the building blocks of almost any AI system. |\n",
      "\n",
      "---\n",
      "\n",
      "### Running the Example\n",
      "\n",
      "```bash\n",
      "# Choose a framework\n",
      "pip install tensorflow   # or torch, or scikit-learn\n",
      "\n",
      "# Run the script\n",
      "python hello_ai_tf.py   # or hello_ai_torch.py, etc.\n",
      "```\n",
      "\n",
      "You should see a number close to **21** (for the regression examples) or the correct class label (for the classifier). That tiny output proves you‚Äôve built, trained, and used an AI model‚Äîexactly what ‚ÄúHello‚ÄØWorld‚Äù means in the world of artificial intelligence. üöÄ\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"groq/compound-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What is the AI equivalent of Hello World?\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e114271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most recent official figure shows that France‚Äôs economy is growing very modestly:\n",
      "\n",
      "* **Quarter‚Äëto‚Äëquarter (Q3‚ÄØ2025)** ‚Äì‚ÄØGDP was **0.90‚ÄØ% higher than a year earlier** (YoY)‚ÄØ„Äêsearch_output_1‚Ä†L1-L4„Äë  \n",
      "* **Full‚Äëyear 2024** ‚Äì‚ÄØGDP grew **1.10‚ÄØ%** over 2023 (the latest annual number released)‚ÄØ„Äêsearch_output_1‚Ä†L13-L16„Äë\n",
      "\n",
      "So the current GDP growth rate is roughly **0.9‚ÄØ% YoY (Q3‚ÄØ2025)**, with the most recent full‚Äëyear estimate at **1.1‚ÄØ% for 2024**.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import requests\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "\n",
    ")\n",
    "\n",
    "def search_web(query):\n",
    "    \"\"\"Example tool to search DuckDuckGo.\"\"\"\n",
    "    resp = requests.get(\"https://api.duckduckgo.com\", params={\"q\": query, \"format\": \"json\"})\n",
    "    return resp.json().get(\"AbstractText\", \"No info found\")\n",
    "\n",
    "def agent(prompt):\n",
    "    \"\"\"Simple agent that can decide to use a tool.\"\"\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"groq/compound-mini\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an assistant that can use the search_web() tool.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "print(agent(\"Find the current GDP growth rate of France\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
