{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c9e6a8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mlflow\n",
    "import optuna\n",
    "import mlflow.sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.inspection import permutation_importance\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "02f7289c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>implicite_fund_rate</th>\n",
       "      <th>observation_date</th>\n",
       "      <th>FEDFUNDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>1.230</td>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>1.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-02-01</td>\n",
       "      <td>1.260</td>\n",
       "      <td>2003-02-01</td>\n",
       "      <td>1.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-03-01</td>\n",
       "      <td>1.250</td>\n",
       "      <td>2003-03-01</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-04-01</td>\n",
       "      <td>1.250</td>\n",
       "      <td>2003-04-01</td>\n",
       "      <td>1.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-05-01</td>\n",
       "      <td>1.250</td>\n",
       "      <td>2003-05-01</td>\n",
       "      <td>1.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>2025-05-01</td>\n",
       "      <td>4.330</td>\n",
       "      <td>2025-05-01</td>\n",
       "      <td>4.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>4.330</td>\n",
       "      <td>2025-06-01</td>\n",
       "      <td>4.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>4.330</td>\n",
       "      <td>2025-07-01</td>\n",
       "      <td>4.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>2025-08-01</td>\n",
       "      <td>4.330</td>\n",
       "      <td>2025-08-01</td>\n",
       "      <td>4.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>4.225</td>\n",
       "      <td>2025-09-01</td>\n",
       "      <td>4.22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>273 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  implicite_fund_rate observation_date  FEDFUNDS\n",
       "0   2003-01-01                1.230       2003-01-01      1.24\n",
       "1   2003-02-01                1.260       2003-02-01      1.26\n",
       "2   2003-03-01                1.250       2003-03-01      1.25\n",
       "3   2003-04-01                1.250       2003-04-01      1.26\n",
       "4   2003-05-01                1.250       2003-05-01      1.26\n",
       "..         ...                  ...              ...       ...\n",
       "268 2025-05-01                4.330       2025-05-01      4.33\n",
       "269 2025-06-01                4.330       2025-06-01      4.33\n",
       "270 2025-07-01                4.330       2025-07-01      4.33\n",
       "271 2025-08-01                4.330       2025-08-01      4.33\n",
       "272 2025-09-01                4.225       2025-09-01      4.22\n",
       "\n",
       "[273 rows x 4 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EFFR = pd.read_csv(\"FEDFUNDS.csv\", sep=\",\", )\n",
    "FFF = pd.read_csv(\"Federal_Fund_Future.csv\", sep=\";\")\n",
    "\n",
    "# Convertir les colonnes en type date\n",
    "EFFR['observation_date'] = pd.to_datetime(EFFR['observation_date'])  \n",
    "FFF['Date'] = pd.to_datetime(FFF['Date'])    # Remplace 'date' par le nom de la colonne appropriée\n",
    "FFF = FFF.drop(columns=['Open', 'High', 'Low', 'Vol.', 'Change %'], errors='ignore')\n",
    "FFF['implicite_fund_rate'] = 100 - FFF['Price']\n",
    "merged_df = pd.merge(FFF[['Date', 'implicite_fund_rate']], EFFR[['observation_date', 'FEDFUNDS']], \n",
    "                      left_on='Date', right_on='observation_date', how='inner')\n",
    "merged_df = merged_df.sort_values('Date').reset_index(drop=True)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5bad87eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "merged_df_=merged_df.copy()\n",
    "\n",
    "n_lags = 6  # number of previous months to use\n",
    "\n",
    "merged_df_['spread'] = merged_df_['implicite_fund_rate'] - merged_df_['FEDFUNDS']\n",
    "\n",
    "\n",
    "for i in range(1, n_lags + 1):\n",
    "    merged_df_[f'implicite_fund_rate_lag_{i}'] = merged_df_['implicite_fund_rate'].shift(i)\n",
    "\n",
    "n_lags_spread = 3\n",
    "for i in range(1, n_lags_spread + 1):\n",
    "    merged_df_[f'spread_lag_{i}'] = merged_df_['spread'].shift(i)\n",
    "\n",
    "# Nettoyer données\n",
    "merged_df_ = merged_df_.dropna()\n",
    "\n",
    "\n",
    "merged_df_['FEDFUNDS_change'] = merged_df_['FEDFUNDS'].diff() # variation au prochain pas de temps\n",
    "merged_df_['target'] = (merged_df_['FEDFUNDS_change'] > 0).astype(int)  # 1 si hausse, 0 sinon\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "aad46f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    147\n",
       "1    120\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_[\"target\"].value_counts()#use accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "96169094",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def check_params(allowed,kwargs):\n",
    "\n",
    "\n",
    "    for key,val in kwargs.items():\n",
    "\n",
    "                if key not in allowed:\n",
    "                    raise ValueError(f\"{key} unrecongized, use : {allowed.keys()}\")\n",
    "                if val not in allowed[key]:\n",
    "                    raise ValueError(f\"{val} unrecongized, for {key} use : {allowed[key]}\")\n",
    "\n",
    "class MlFlowModel:\n",
    "\n",
    "    def __init__(self,exper_name,model_instance,**kwargs):\n",
    "\n",
    "        \"\"\"\n",
    "        supports two models: logistic regression and random forest only \n",
    "\n",
    "        \"\"\"\n",
    "        self.model_instance=model_instance\n",
    "        self.exper_name=exper_name\n",
    "        self.kwargs=kwargs\n",
    "        self.n_trials=10\n",
    "\n",
    "        if isinstance(self.model_instance,type):\n",
    "            raise ValueError(f\"dont forget parantheses in your model_instance\")\n",
    "        \n",
    "\n",
    "        if self.model_instance.__class__ is not   LogisticRegression and  self.model_instance.__class__ is not RandomForestClassifier:\n",
    "            raise ValueError('sorry, we can use logistic regression and random forest only for the moment ')\n",
    "\n",
    "\n",
    "        if self.model_instance.__class__ is  LogisticRegression:\n",
    "            allowed={\n",
    "                \"penalty\" : [\"l1\", \"l2\", \"elasticnet\", None],\n",
    "                \"solver\" : \"saga\"\n",
    "            }\n",
    "\n",
    "            if \"penalty\" not in kwargs.keys() or \"solver\" not in kwargs.keys():\n",
    "                raise ValueError(\"need to specify both penalty and solver for logistic regression \")\n",
    "\n",
    "        if self.model_instance.__class__ is  RandomForestClassifier:\n",
    "            allowed={\n",
    "                \"max_features\" : [\"sqrt\", \"log2\", None],\n",
    "                \"criterion\" : [\"gini\", \"entropy\", \"log_loss\"]\n",
    "            }\n",
    "            if \"max_features\" not in kwargs.keys() or \"criterion\" not in kwargs.keys():\n",
    "                raise ValueError(\"need to specify both max_features and criterion for randm forest \")\n",
    "\n",
    "        \n",
    "        check_params(allowed,self.kwargs)\n",
    "\n",
    "    \n",
    "    def objective(self,trial):\n",
    "                \n",
    "\n",
    "                if self.model_instance.__class__ is  LogisticRegression:\n",
    "\n",
    "                    if \"elasticnet\" == self.kwargs[\"penalty\"]:\n",
    "                        # Define hyperparameter search space\n",
    "                        params_candidate_space={\n",
    "                            \"l1_ratio\": trial.suggest_float(\"l1_ratio\", 0.1, 0.9),\n",
    "                            \"C\":  trial.suggest_float(\"C\", 0.1, 10),\n",
    "                        }\n",
    "                    elif \"l1\" == self.kwargs[\"penalty\"] or \"l2\" == self.kwargs[\"penalty\"]:\n",
    "                        # Define hyperparameter search space\n",
    "                        params_candidate_space={\n",
    "                            \"C\":  trial.suggest_float(\"C\", 0.1, 10),\n",
    "                        }\n",
    "                    \n",
    "                if self.model_instance.__class__ is  RandomForestClassifier:\n",
    "\n",
    "                    params_candidate_space={\n",
    "                            'max_depth': trial.suggest_int(\"max_depth\", 10, 50),\n",
    "                            \"min_samples_split\":  trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "                            \"min_samples_leaf\":  trial.suggest_int(\"min_samples_leaf\", 1, 4),\n",
    "                 \n",
    "                        }\n",
    "\n",
    "                \n",
    "\n",
    "                model = self.model_instance.__class__(\n",
    "                    **params_candidate_space, \n",
    "                    **self.fixed_params,\n",
    "                    **self.kwargs  \n",
    "                )\n",
    "            \n",
    "\n",
    "                model.fit(self.X_train, self.y_train)\n",
    "\n",
    "\n",
    "                #log_loss is sklearn is negative loglikelihood so we minimise it\n",
    "                #in randomforest if we use gini, then we need to modify this line, but we do simple:\n",
    "                score = log_loss(self.y_train, model.predict_proba(self.X_train))\n",
    "\n",
    "                return score\n",
    "\n",
    "\n",
    "\n",
    "    def run_optuna_study(self):\n",
    "\n",
    "        storage = f\"sqlite:///optuna_{self.exper_name}.db\"\n",
    "        study = optuna.create_study(\n",
    "                            direction=\"minimize\", \n",
    "                            study_name=f\"{self.exper_name}\",\n",
    "                            storage=storage,\n",
    "                            load_if_exists=True\n",
    "        )  # 'minimize' for loss functions\n",
    "        study.optimize(self.objective, n_trials=self.n_trials)\n",
    "        study_best_params=study.best_params\n",
    "        return study_best_params\n",
    "\n",
    "    def train(self,merged_df_,feature_columns):\n",
    "        \n",
    "        with mlflow.start_run(run_name=f\"{self.exper_name}_FedFunds\"):\n",
    "        \n",
    "                mlflow.log_param(\"model_type\", self.model_instance.__class__.__name__)\n",
    "                mlflow.log_param(\"variables\", feature_columns)\n",
    "                mlflow.log_param(\"scaler\", \"StandardScaler\")\n",
    "                mlflow.log_param(\"train_test_split\", \"80/20 time series\")\n",
    "                mlflow.log_param(\"kwargs\",self.kwargs)\n",
    "                \n",
    "                #do easy splits and transforms:\n",
    "                X = merged_df_[feature_columns]\n",
    "                y = merged_df_['target']\n",
    "                split_idx = int(len(merged_df_) * 0.8)\n",
    "                self.X_train, self.X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "                self.y_train, self.y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "                #always standartise variables for logit \n",
    "                if self.model_instance.__class__ is  LogisticRegression:\n",
    "                    scaler = StandardScaler()\n",
    "                    self.X_train = scaler.fit_transform(self.X_train)\n",
    "                    self.X_test = scaler.transform(self.X_test)\n",
    "\n",
    "                # Model penalisations\n",
    "\n",
    "                if self.model_instance.__class__ is  LogisticRegression:\n",
    "                    print(\"normalising data\")\n",
    "                    self.fixed_params={\n",
    "                        \n",
    "                        \"class_weight\" : 'balanced',  \n",
    "                        \"random_state\" : 42,\n",
    "                    }\n",
    "                \n",
    "\n",
    "                    if self.kwargs[\"penalty\"] is not None:\n",
    "                        #in this case need to search space for best hyperparameter\n",
    "                        study_best_params=self.run_optuna_study()\n",
    "                        print(\"Best Hyperparameters:\",study_best_params)\n",
    "                    else:\n",
    "                        study_best_params={}\n",
    "\n",
    "                if self.model_instance.__class__ is  RandomForestClassifier:\n",
    "                    self.fixed_params={\n",
    "                        \"n_estimators\" : 150,\n",
    "                        \"class_weight\" : 'balanced',  \n",
    "                       \n",
    "                    }\n",
    "                    study_best_params=self.run_optuna_study()\n",
    "                    print(\"Best Hyperparameters:\",study_best_params)\n",
    "                    \n",
    "\n",
    "                        \n",
    "                model = self.model_instance.__class__(\n",
    "                     **self.fixed_params,\n",
    "                     **study_best_params,\n",
    "                     **self.kwargs                \n",
    "                )\n",
    "                print(\"-----------\")\n",
    "                \n",
    "\n",
    "               \n",
    "                model.fit(self.X_train, self.y_train)\n",
    "                # Predictions\n",
    "                y_pred = model.predict(self.X_test)\n",
    "                \n",
    "                acc = accuracy_score(self.y_test, y_pred)\n",
    "                mlflow.log_metric(\"accuracy\", acc)\n",
    "                mlflow.sklearn.log_model(model, name=\"model\")\n",
    "\n",
    "                print(f\"Run logged to MLflow: accuracy={acc:.4f}\")\n",
    "\n",
    "\n",
    "def var_selection_with_permutation(model,X,y,threshold_below_which_to_drop=0.01):\n",
    "\n",
    "    '''\n",
    "    supports any classification model, models implying gradient descent (parametric models) require dataset to be normalised \n",
    "    models such as random forests or other non gradient tree models do not require variable standartisation \n",
    "    '''\n",
    "    \n",
    "    split_idx = int(len(X) * 0.8)\n",
    "\n",
    "    X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "    y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]\n",
    "\n",
    "    if model.__class__.__name__ in [\"LogisticRegression\",]:\n",
    "        \n",
    "        scaler = StandardScaler().set_output(transform=\"pandas\")\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    result = permutation_importance(model, X_test, y_test, n_repeats=10, random_state=42,scoring=\"accuracy\")\n",
    "\n",
    "    perm_importances = pd.DataFrame({\n",
    "        'feature': X_test.columns,\n",
    "        'importance_mean': result.importances_mean,\n",
    "        'importance_std': result.importances_std\n",
    "    })\n",
    "    \n",
    "    return perm_importances[perm_importances[\"importance_mean\"]>threshold_below_which_to_drop][\"feature\"].tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cda54a",
   "metadata": {},
   "source": [
    "Gradient based models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d7771541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nb variables before permutation selection ': 3, 'nb variables after permutation selection ': 3}\n",
      "normalising data\n",
      "-----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/11/13 22:26:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run logged to MLflow: accuracy=0.6481\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=42, class_weight='balanced')\n",
    "feature_columns =  [f'spread_lag_{i}' for i in range(1, n_lags_spread + 1)] \n",
    "X = merged_df_[feature_columns]\n",
    "y = merged_df_['target']\n",
    "feature_columns_after_permutation_test=var_selection_with_permutation(model,X,y)\n",
    "print(\n",
    "{\n",
    "    \"nb variables before permutation selection \" : len(feature_columns),\n",
    "    \"nb variables after permutation selection \" : len(feature_columns_after_permutation_test)\n",
    "\n",
    "}\n",
    ")\n",
    "model=MlFlowModel(\"lrsimplest\",LogisticRegression(),penalty=None,solver=\"saga\")\n",
    "model.train(merged_df_,feature_columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d7bbc859",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract new features with AI AGENT -> finish code after\n",
    "df = pd.read_csv(\"macro_features_monthly.csv\")\n",
    "df['DATE'] = pd.to_datetime(df['DATE'], dayfirst=True)\n",
    "\n",
    "\n",
    "df['DATE'] = df['DATE'].values.astype('datetime64[M]')\n",
    "df_=df.copy()\n",
    "n_lags=4\n",
    "for el in df_.columns[1:].tolist():\n",
    "    for i in range(1, n_lags + 1):\n",
    "        df_[f'{el}_{i}'] = df_[el].shift(i)\n",
    "df_ = df_.dropna()\n",
    "final=pd.merge(merged_df_, df_, \n",
    "                      left_on='Date', right_on='DATE', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5f4c0947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DATE', 'CPIAUCSL', 'PCEPI', 'UNRATE', 'PAYEMS', 'GDP', 'INDPRO',\n",
       "       'FinStress'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "eb8f620c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [ s for s in final.columns if s[-2] == '_' and s[-1].isdigit()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fd9ffaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalising data\n",
      "-----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/11/13 22:25:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run logged to MLflow: accuracy=0.6111\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model=MlFlowModel(\"lr-all-vars\",LogisticRegression(),penalty=None,solver=\"saga\")\n",
    "model.train(final,feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f0ec0cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalising data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 21:36:22,674] A new study created in RDB with name: lr-all-vars-elnet\n",
      "[I 2025-11-13 21:36:22,838] Trial 0 finished with value: 0.5259614301045616 and parameters: {'l1_ratio': 0.6518244308407477, 'C': 8.726561244029567}. Best is trial 0 with value: 0.5259614301045616.\n",
      "[I 2025-11-13 21:36:22,989] Trial 1 finished with value: 0.5259045274812394 and parameters: {'l1_ratio': 0.4022262885635456, 'C': 8.02802110164171}. Best is trial 1 with value: 0.5259045274812394.\n",
      "[I 2025-11-13 21:36:23,117] Trial 2 finished with value: 0.5276832404314976 and parameters: {'l1_ratio': 0.5401095795699872, 'C': 5.449078283412642}. Best is trial 1 with value: 0.5259045274812394.\n",
      "[I 2025-11-13 21:36:23,262] Trial 3 finished with value: 0.5684442893535757 and parameters: {'l1_ratio': 0.5848653662095064, 'C': 0.5322278093855329}. Best is trial 1 with value: 0.5259045274812394.\n",
      "[I 2025-11-13 21:36:23,385] Trial 4 finished with value: 0.5299672560177435 and parameters: {'l1_ratio': 0.40749396759304224, 'C': 3.514942993556398}. Best is trial 1 with value: 0.5259045274812394.\n",
      "[I 2025-11-13 21:36:23,525] Trial 5 finished with value: 0.5296116301155795 and parameters: {'l1_ratio': 0.7436824276421191, 'C': 4.242597180310406}. Best is trial 1 with value: 0.5259045274812394.\n",
      "[I 2025-11-13 21:36:23,654] Trial 6 finished with value: 0.5271568935486792 and parameters: {'l1_ratio': 0.4953916811960256, 'C': 5.990038463842282}. Best is trial 1 with value: 0.5259045274812394.\n",
      "[I 2025-11-13 21:36:23,791] Trial 7 finished with value: 0.5695369729676838 and parameters: {'l1_ratio': 0.356227346189389, 'C': 0.41571904234992374}. Best is trial 1 with value: 0.5259045274812394.\n",
      "[I 2025-11-13 21:36:23,919] Trial 8 finished with value: 0.5290785837290999 and parameters: {'l1_ratio': 0.7339305343006489, 'C': 4.5878098092119}. Best is trial 1 with value: 0.5259045274812394.\n",
      "[I 2025-11-13 21:36:24,061] Trial 9 finished with value: 0.5309932658862954 and parameters: {'l1_ratio': 0.4320851237093932, 'C': 3.1020504475178496}. Best is trial 1 with value: 0.5259045274812394.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'l1_ratio': 0.4022262885635456, 'C': 8.02802110164171}\n",
      "-----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/11/13 21:36:27 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run logged to MLflow: accuracy=0.8148\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model=MlFlowModel(\"lr-all-vars-elnet\",LogisticRegression(),penalty=\"elasticnet\",solver=\"saga\")\n",
    "model.train(final,feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e7d38f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalising data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 21:36:43,406] A new study created in RDB with name: lr-all-vars-l1\n",
      "[I 2025-11-13 21:36:43,597] Trial 0 finished with value: 0.5330379585010842 and parameters: {'C': 3.00657035841268}. Best is trial 0 with value: 0.5330379585010842.\n",
      "[I 2025-11-13 21:36:43,701] Trial 1 finished with value: 0.5336040421656751 and parameters: {'C': 2.8476418651802975}. Best is trial 0 with value: 0.5330379585010842.\n",
      "[I 2025-11-13 21:36:43,834] Trial 2 finished with value: 0.569874988640743 and parameters: {'C': 0.6376796339358232}. Best is trial 0 with value: 0.5330379585010842.\n",
      "[I 2025-11-13 21:36:43,939] Trial 3 finished with value: 0.5672601263757869 and parameters: {'C': 0.6898050241395346}. Best is trial 0 with value: 0.5330379585010842.\n",
      "[I 2025-11-13 21:36:44,083] Trial 4 finished with value: 0.5263818271523549 and parameters: {'C': 8.756330034724071}. Best is trial 4 with value: 0.5263818271523549.\n",
      "[I 2025-11-13 21:36:44,203] Trial 5 finished with value: 0.5356721908354839 and parameters: {'C': 2.4068896269717706}. Best is trial 4 with value: 0.5263818271523549.\n",
      "[I 2025-11-13 21:36:44,309] Trial 6 finished with value: 0.5844481798768619 and parameters: {'C': 0.451712483974286}. Best is trial 4 with value: 0.5263818271523549.\n",
      "[I 2025-11-13 21:36:44,410] Trial 7 finished with value: 0.6051129626340843 and parameters: {'C': 0.2617753950996873}. Best is trial 4 with value: 0.5263818271523549.\n",
      "[I 2025-11-13 21:36:44,520] Trial 8 finished with value: 0.5260545210137466 and parameters: {'C': 9.606003882764288}. Best is trial 8 with value: 0.5260545210137466.\n",
      "[I 2025-11-13 21:36:44,658] Trial 9 finished with value: 0.5266988393751113 and parameters: {'C': 8.067999648568613}. Best is trial 8 with value: 0.5260545210137466.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'C': 9.606003882764288}\n",
      "-----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/11/13 21:36:47 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run logged to MLflow: accuracy=0.8148\n"
     ]
    }
   ],
   "source": [
    "model=MlFlowModel(\"lr-all-vars-l1\",LogisticRegression(),penalty=\"l1\",solver=\"saga\")\n",
    "model.train(final,feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7dfe035e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nb variables before permutation selection ': 37, 'nb variables after permutation selection ': 11}\n",
      "normalising data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 21:37:59,855] A new study created in RDB with name: lr-per-vars0.01-elnet\n",
      "[I 2025-11-13 21:38:00,015] Trial 0 finished with value: 0.6340546017231301 and parameters: {'l1_ratio': 0.46645173945990737, 'C': 0.21945811587525393}. Best is trial 0 with value: 0.6340546017231301.\n",
      "[I 2025-11-13 21:38:00,157] Trial 1 finished with value: 0.5645381584513496 and parameters: {'l1_ratio': 0.17205941459952462, 'C': 7.575706047975876}. Best is trial 1 with value: 0.5645381584513496.\n",
      "[I 2025-11-13 21:38:00,308] Trial 2 finished with value: 0.5717693813694031 and parameters: {'l1_ratio': 0.21120937483670563, 'C': 3.076176934629406}. Best is trial 1 with value: 0.5645381584513496.\n",
      "[I 2025-11-13 21:38:00,502] Trial 3 finished with value: 0.5612342427182211 and parameters: {'l1_ratio': 0.7844675733909673, 'C': 9.53618313612696}. Best is trial 3 with value: 0.5612342427182211.\n",
      "[I 2025-11-13 21:38:00,645] Trial 4 finished with value: 0.5645708905775546 and parameters: {'l1_ratio': 0.10264023511110727, 'C': 7.914778859211637}. Best is trial 3 with value: 0.5612342427182211.\n",
      "[I 2025-11-13 21:38:00,777] Trial 5 finished with value: 0.5657363768257995 and parameters: {'l1_ratio': 0.25624854451095735, 'C': 5.8494947774833745}. Best is trial 3 with value: 0.5612342427182211.\n",
      "[I 2025-11-13 21:38:00,924] Trial 6 finished with value: 0.5617479300505455 and parameters: {'l1_ratio': 0.653412275824452, 'C': 9.417470307598713}. Best is trial 3 with value: 0.5612342427182211.\n",
      "[I 2025-11-13 21:38:01,040] Trial 7 finished with value: 0.5779299566698876 and parameters: {'l1_ratio': 0.70244198479337, 'C': 1.516500986045479}. Best is trial 3 with value: 0.5612342427182211.\n",
      "[I 2025-11-13 21:38:01,199] Trial 8 finished with value: 0.5663275942360755 and parameters: {'l1_ratio': 0.7708721078061872, 'C': 3.4810410471357804}. Best is trial 3 with value: 0.5612342427182211.\n",
      "[I 2025-11-13 21:38:01,326] Trial 9 finished with value: 0.5769770339170168 and parameters: {'l1_ratio': 0.29377348882226606, 'C': 1.9917724020308463}. Best is trial 3 with value: 0.5612342427182211.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'l1_ratio': 0.7844675733909673, 'C': 9.53618313612696}\n",
      "-----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/11/13 21:38:04 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run logged to MLflow: accuracy=0.8889\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=42, class_weight='balanced')\n",
    "feature_columns =  [ s for s in final.columns if s[-2] == '_' and s[-1].isdigit()]\n",
    "X = final[feature_columns]\n",
    "y = final['target']\n",
    "feature_columns_after_permutation_test=var_selection_with_permutation(model,X,y)\n",
    "print(\n",
    "{\n",
    "    \"nb variables before permutation selection \" : len(feature_columns),\n",
    "    \"nb variables after permutation selection \" : len(feature_columns_after_permutation_test)\n",
    "\n",
    "}\n",
    ")\n",
    "model=MlFlowModel(\"lr-per-vars0.01-elnet\",LogisticRegression(),penalty=\"elasticnet\",solver=\"saga\")\n",
    "model.train(final,feature_columns_after_permutation_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6dc1bfdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nb variables before permutation selection ': 37, 'nb variables after permutation selection ': 10}\n",
      "normalising data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 21:38:36,181] A new study created in RDB with name: lr-per-vars0.02-elnet\n",
      "[I 2025-11-13 21:38:36,326] Trial 0 finished with value: 0.5625799457796318 and parameters: {'l1_ratio': 0.6924280386143199, 'C': 8.293790572683685}. Best is trial 0 with value: 0.5625799457796318.\n",
      "[I 2025-11-13 21:38:36,458] Trial 1 finished with value: 0.6115209634002232 and parameters: {'l1_ratio': 0.21525778385165442, 'C': 0.4272315713993765}. Best is trial 0 with value: 0.5625799457796318.\n",
      "[I 2025-11-13 21:38:36,589] Trial 2 finished with value: 0.5646687202353088 and parameters: {'l1_ratio': 0.1495823409752366, 'C': 8.400189546594419}. Best is trial 0 with value: 0.5625799457796318.\n",
      "[I 2025-11-13 21:38:36,782] Trial 3 finished with value: 0.5656112825728503 and parameters: {'l1_ratio': 0.1768549667965914, 'C': 6.939857703652378}. Best is trial 0 with value: 0.5625799457796318.\n",
      "[I 2025-11-13 21:38:36,938] Trial 4 finished with value: 0.5656831785208424 and parameters: {'l1_ratio': 0.24579334157872773, 'C': 6.512055262067833}. Best is trial 0 with value: 0.5625799457796318.\n",
      "[I 2025-11-13 21:38:37,105] Trial 5 finished with value: 0.5644784244320087 and parameters: {'l1_ratio': 0.648255818668926, 'C': 5.602932085251236}. Best is trial 0 with value: 0.5625799457796318.\n",
      "[I 2025-11-13 21:38:37,286] Trial 6 finished with value: 0.5655855967025961 and parameters: {'l1_ratio': 0.33534522778701376, 'C': 6.166561370712239}. Best is trial 0 with value: 0.5625799457796318.\n",
      "[I 2025-11-13 21:38:37,397] Trial 7 finished with value: 0.5651997346575038 and parameters: {'l1_ratio': 0.3798695065323243, 'C': 6.3442065072739}. Best is trial 0 with value: 0.5625799457796318.\n",
      "[I 2025-11-13 21:38:37,509] Trial 8 finished with value: 0.5643620403318075 and parameters: {'l1_ratio': 0.5230996015851702, 'C': 6.506464012276524}. Best is trial 0 with value: 0.5625799457796318.\n",
      "[I 2025-11-13 21:38:37,698] Trial 9 finished with value: 0.5833816312663191 and parameters: {'l1_ratio': 0.7129563368266288, 'C': 1.0765278964715779}. Best is trial 0 with value: 0.5625799457796318.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'l1_ratio': 0.6924280386143199, 'C': 8.293790572683685}\n",
      "-----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/11/13 21:38:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run logged to MLflow: accuracy=0.9259\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=42, class_weight='balanced')\n",
    "feature_columns =  [ s for s in final.columns if s[-2] == '_' and s[-1].isdigit()]\n",
    "X = final[feature_columns]\n",
    "y = final['target']\n",
    "feature_columns_after_permutation_test=var_selection_with_permutation(model,X,y,0.02)\n",
    "print(\n",
    "{\n",
    "    \"nb variables before permutation selection \" : len(feature_columns),\n",
    "    \"nb variables after permutation selection \" : len(feature_columns_after_permutation_test)\n",
    "\n",
    "}\n",
    ")\n",
    "model=MlFlowModel(\"lr-per-vars0.02-elnet\",LogisticRegression(),penalty=\"elasticnet\",solver=\"saga\")\n",
    "model.train(final,feature_columns_after_permutation_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c84cdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nb variables before permutation selection ': 37, 'nb variables after permutation selection ': 10}\n",
      "normalising data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 21:38:59,011] A new study created in RDB with name: lr-per-vars0.02-l1\n",
      "[I 2025-11-13 21:38:59,223] Trial 0 finished with value: 0.5665365502330372 and parameters: {'C': 2.7244807514662597}. Best is trial 0 with value: 0.5665365502330372.\n",
      "[I 2025-11-13 21:38:59,345] Trial 1 finished with value: 0.5628350025819375 and parameters: {'C': 4.987497787647181}. Best is trial 1 with value: 0.5628350025819375.\n",
      "[I 2025-11-13 21:38:59,463] Trial 2 finished with value: 0.5913303586898634 and parameters: {'C': 0.6926224282170393}. Best is trial 1 with value: 0.5628350025819375.\n",
      "[I 2025-11-13 21:38:59,610] Trial 3 finished with value: 0.5609561847354283 and parameters: {'C': 9.741431163041298}. Best is trial 3 with value: 0.5609561847354283.\n",
      "[I 2025-11-13 21:38:59,699] Trial 4 finished with value: 0.5675685301423785 and parameters: {'C': 2.4147884959961474}. Best is trial 3 with value: 0.5609561847354283.\n",
      "[I 2025-11-13 21:38:59,806] Trial 5 finished with value: 0.568858656729954 and parameters: {'C': 2.120556703142064}. Best is trial 3 with value: 0.5609561847354283.\n",
      "[I 2025-11-13 21:38:59,915] Trial 6 finished with value: 0.5817373332531808 and parameters: {'C': 0.9380353709309274}. Best is trial 3 with value: 0.5609561847354283.\n",
      "[I 2025-11-13 21:39:00,034] Trial 7 finished with value: 0.5638287798482415 and parameters: {'C': 4.058578761654032}. Best is trial 3 with value: 0.5609561847354283.\n",
      "[I 2025-11-13 21:39:00,138] Trial 8 finished with value: 0.5617261394269359 and parameters: {'C': 6.898472389977552}. Best is trial 3 with value: 0.5609561847354283.\n",
      "[I 2025-11-13 21:39:00,249] Trial 9 finished with value: 0.5639414050952118 and parameters: {'C': 3.9775723202989033}. Best is trial 3 with value: 0.5609561847354283.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'C': 9.741431163041298}\n",
      "-----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/11/13 21:39:03 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run logged to MLflow: accuracy=0.9259\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=42, class_weight='balanced')\n",
    "feature_columns =  [ s for s in final.columns if s[-2] == '_' and s[-1].isdigit()]\n",
    "X = final[feature_columns]\n",
    "y = final['target']\n",
    "feature_columns_after_permutation_test=var_selection_with_permutation(model,X,y,0.02)\n",
    "print(\n",
    "{\n",
    "    \"nb variables before permutation selection \" : len(feature_columns),\n",
    "    \"nb variables after permutation selection \" : len(feature_columns_after_permutation_test)\n",
    "\n",
    "}\n",
    ")\n",
    "model=MlFlowModel(\"lr-per-vars0.02-l1\",LogisticRegression(),penalty=\"l1\",solver=\"saga\")\n",
    "model.train(final,feature_columns_after_permutation_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abbc0c6",
   "metadata": {},
   "source": [
    "Tree models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "537b8cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 21:43:36,491] A new study created in RDB with name: rf-all-vars-sqrt-gini\n",
      "[I 2025-11-13 21:43:36,980] Trial 0 finished with value: 0.31180734629285534 and parameters: {'max_depth': 13, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.31180734629285534.\n",
      "[I 2025-11-13 21:43:37,428] Trial 1 finished with value: 0.27003947065336487 and parameters: {'max_depth': 13, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 1 with value: 0.27003947065336487.\n",
      "[I 2025-11-13 21:43:37,903] Trial 2 finished with value: 0.18240230400532625 and parameters: {'max_depth': 23, 'min_samples_split': 4, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.18240230400532625.\n",
      "[I 2025-11-13 21:43:38,361] Trial 3 finished with value: 0.21448407334194788 and parameters: {'max_depth': 40, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.18240230400532625.\n",
      "[I 2025-11-13 21:43:38,859] Trial 4 finished with value: 0.27355673839178396 and parameters: {'max_depth': 40, 'min_samples_split': 2, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.18240230400532625.\n",
      "[I 2025-11-13 21:43:39,281] Trial 5 finished with value: 0.21546754658132433 and parameters: {'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.18240230400532625.\n",
      "[I 2025-11-13 21:43:39,755] Trial 6 finished with value: 0.307341829048961 and parameters: {'max_depth': 20, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.18240230400532625.\n",
      "[I 2025-11-13 21:43:40,212] Trial 7 finished with value: 0.30839006638717126 and parameters: {'max_depth': 15, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.18240230400532625.\n",
      "[I 2025-11-13 21:43:40,660] Trial 8 finished with value: 0.27101254878684705 and parameters: {'max_depth': 50, 'min_samples_split': 10, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.18240230400532625.\n",
      "[I 2025-11-13 21:43:41,127] Trial 9 finished with value: 0.22106066842072547 and parameters: {'max_depth': 36, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.18240230400532625.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 23, 'min_samples_split': 4, 'min_samples_leaf': 1}\n",
      "-----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/11/13 21:43:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run logged to MLflow: accuracy=0.6296\n"
     ]
    }
   ],
   "source": [
    "feature_columns =  [ s for s in final.columns if s[-2] == '_' and s[-1].isdigit()]\n",
    "model=MlFlowModel(\"rf-all-vars-sqrt-gini\",RandomForestClassifier(),max_features=\"sqrt\",criterion=\"gini\")\n",
    "model.train(final,feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "feca3c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 21:44:21,908] A new study created in RDB with name: rf-all-vars-sqrt-entropy\n",
      "[I 2025-11-13 21:44:22,382] Trial 0 finished with value: 0.2955613610782683 and parameters: {'max_depth': 47, 'min_samples_split': 7, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.2955613610782683.\n",
      "[I 2025-11-13 21:44:22,850] Trial 1 finished with value: 0.2943127983110874 and parameters: {'max_depth': 24, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.2943127983110874.\n",
      "[I 2025-11-13 21:44:23,339] Trial 2 finished with value: 0.20340014105745388 and parameters: {'max_depth': 31, 'min_samples_split': 3, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.20340014105745388.\n",
      "[I 2025-11-13 21:44:23,797] Trial 3 finished with value: 0.23016930971452096 and parameters: {'max_depth': 45, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 2 with value: 0.20340014105745388.\n",
      "[I 2025-11-13 21:44:24,299] Trial 4 finished with value: 0.2787517747244563 and parameters: {'max_depth': 39, 'min_samples_split': 9, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.20340014105745388.\n",
      "[I 2025-11-13 21:44:24,766] Trial 5 finished with value: 0.29595361440572876 and parameters: {'max_depth': 25, 'min_samples_split': 5, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.20340014105745388.\n",
      "[I 2025-11-13 21:44:25,254] Trial 6 finished with value: 0.2566550082390946 and parameters: {'max_depth': 45, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 2 with value: 0.20340014105745388.\n",
      "[I 2025-11-13 21:44:25,790] Trial 7 finished with value: 0.27483988939510134 and parameters: {'max_depth': 38, 'min_samples_split': 10, 'min_samples_leaf': 2}. Best is trial 2 with value: 0.20340014105745388.\n",
      "[I 2025-11-13 21:44:26,247] Trial 8 finished with value: 0.29779553420603233 and parameters: {'max_depth': 29, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.20340014105745388.\n",
      "[I 2025-11-13 21:44:26,670] Trial 9 finished with value: 0.29431332763602 and parameters: {'max_depth': 40, 'min_samples_split': 2, 'min_samples_leaf': 4}. Best is trial 2 with value: 0.20340014105745388.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 31, 'min_samples_split': 3, 'min_samples_leaf': 2}\n",
      "-----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/11/13 21:44:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run logged to MLflow: accuracy=0.6296\n"
     ]
    }
   ],
   "source": [
    "feature_columns =  [ s for s in final.columns if s[-2] == '_' and s[-1].isdigit()]\n",
    "model=MlFlowModel(\"rf-all-vars-sqrt-entropy\",RandomForestClassifier(),max_features=\"sqrt\",criterion=\"entropy\")\n",
    "model.train(final,feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e1beb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nb variables before permutation selection ': 37, 'nb variables after permutation selection ': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-13 21:47:46,167] A new study created in RDB with name: rf-per-vars0.02-sqrt-logloss\n",
      "[I 2025-11-13 21:47:46,614] Trial 0 finished with value: 0.27360833536187656 and parameters: {'max_depth': 23, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 0 with value: 0.27360833536187656.\n",
      "[I 2025-11-13 21:47:47,025] Trial 1 finished with value: 0.26467643383733996 and parameters: {'max_depth': 10, 'min_samples_split': 8, 'min_samples_leaf': 1}. Best is trial 1 with value: 0.26467643383733996.\n",
      "[I 2025-11-13 21:47:47,501] Trial 2 finished with value: 0.32152465624486354 and parameters: {'max_depth': 46, 'min_samples_split': 4, 'min_samples_leaf': 4}. Best is trial 1 with value: 0.26467643383733996.\n",
      "[I 2025-11-13 21:47:47,957] Trial 3 finished with value: 0.2839479950075895 and parameters: {'max_depth': 19, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 1 with value: 0.26467643383733996.\n",
      "[I 2025-11-13 21:47:48,390] Trial 4 finished with value: 0.23789310441320144 and parameters: {'max_depth': 25, 'min_samples_split': 7, 'min_samples_leaf': 1}. Best is trial 4 with value: 0.23789310441320144.\n",
      "[I 2025-11-13 21:47:48,807] Trial 5 finished with value: 0.16018747069960343 and parameters: {'max_depth': 26, 'min_samples_split': 3, 'min_samples_leaf': 1}. Best is trial 5 with value: 0.16018747069960343.\n",
      "[I 2025-11-13 21:47:49,205] Trial 6 finished with value: 0.2794462860609609 and parameters: {'max_depth': 34, 'min_samples_split': 4, 'min_samples_leaf': 3}. Best is trial 5 with value: 0.16018747069960343.\n",
      "[I 2025-11-13 21:47:49,632] Trial 7 finished with value: 0.279326886100806 and parameters: {'max_depth': 15, 'min_samples_split': 5, 'min_samples_leaf': 3}. Best is trial 5 with value: 0.16018747069960343.\n",
      "[I 2025-11-13 21:47:50,033] Trial 8 finished with value: 0.3235696879612697 and parameters: {'max_depth': 18, 'min_samples_split': 9, 'min_samples_leaf': 4}. Best is trial 5 with value: 0.16018747069960343.\n",
      "[I 2025-11-13 21:47:50,442] Trial 9 finished with value: 0.26939057151258494 and parameters: {'max_depth': 40, 'min_samples_split': 8, 'min_samples_leaf': 2}. Best is trial 5 with value: 0.16018747069960343.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': 26, 'min_samples_split': 3, 'min_samples_leaf': 1}\n",
      "-----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/11/13 21:47:53 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run logged to MLflow: accuracy=0.6111\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression( random_state=42,class_weight='balanced')\n",
    "feature_columns =  [ s for s in final.columns if s[-2] == '_' and s[-1].isdigit()]\n",
    "X = final[feature_columns]\n",
    "y = final['target']\n",
    "feature_columns_after_permutation_test=var_selection_with_permutation(model,X,y,0.02)\n",
    "print(\n",
    "{\n",
    "    \"nb variables before permutation selection \" : len(feature_columns),\n",
    "    \"nb variables after permutation selection \" : len(feature_columns_after_permutation_test)\n",
    "\n",
    "}\n",
    ")\n",
    "model=MlFlowModel(\"rf-per-vars0.02-sqrt-logloss\",RandomForestClassifier(),max_features=\"sqrt\",criterion=\"log_loss\")\n",
    "model.train(final,feature_columns_after_permutation_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "776779fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import mlflow \n",
    "experiments = mlflow.search_experiments()\n",
    "runs=mlflow.search_runs(experiment_ids=[exp.experiment_id for exp in experiments])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8cc5562d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>status</th>\n",
       "      <th>run_id</th>\n",
       "      <th>metrics.accuracy</th>\n",
       "      <th>params.model_type</th>\n",
       "      <th>params.variables</th>\n",
       "      <th>params.kwargs</th>\n",
       "      <th>tags.mlflow.runName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FINISHED</td>\n",
       "      <td>463ad99c2bbb42d2bd44f4290e2632f1</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>['implicite_fund_rate_lag_1', 'implicite_fund_...</td>\n",
       "      <td>{'penalty': 'l1', 'solver': 'saga'}</td>\n",
       "      <td>lr-per-vars0.02-l1_FedFunds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FINISHED</td>\n",
       "      <td>bb0460e0e5424f0d89d024fd7ebe0dc3</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>['implicite_fund_rate_lag_1', 'implicite_fund_...</td>\n",
       "      <td>{'penalty': 'elasticnet', 'solver': 'saga'}</td>\n",
       "      <td>lr-per-vars0.02-elnet_FedFunds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FINISHED</td>\n",
       "      <td>d59f138ec0b84ef1bb32cf63b2f2cfb2</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>['implicite_fund_rate_lag_1', 'implicite_fund_...</td>\n",
       "      <td>{'penalty': 'elasticnet', 'solver': 'saga'}</td>\n",
       "      <td>lr-per-vars0.01-elnet_FedFunds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FINISHED</td>\n",
       "      <td>1a9faa98a77c4a07967372918d007932</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>['implicite_fund_rate_lag_1', 'implicite_fund_...</td>\n",
       "      <td>{'penalty': None, 'solver': 'saga'}</td>\n",
       "      <td>lr-all-vars_FedFunds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FINISHED</td>\n",
       "      <td>e48e00ddea284b2ca52294c47dfda620</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>['implicite_fund_rate_lag_1', 'implicite_fund_...</td>\n",
       "      <td>{'penalty': 'elasticnet', 'solver': 'saga'}</td>\n",
       "      <td>lr-all-vars-elnet_FedFunds</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     status                            run_id  metrics.accuracy  \\\n",
       "0  FINISHED  463ad99c2bbb42d2bd44f4290e2632f1          0.925926   \n",
       "1  FINISHED  bb0460e0e5424f0d89d024fd7ebe0dc3          0.925926   \n",
       "2  FINISHED  d59f138ec0b84ef1bb32cf63b2f2cfb2          0.888889   \n",
       "3  FINISHED  1a9faa98a77c4a07967372918d007932          0.814815   \n",
       "4  FINISHED  e48e00ddea284b2ca52294c47dfda620          0.814815   \n",
       "\n",
       "    params.model_type                                   params.variables  \\\n",
       "0  LogisticRegression  ['implicite_fund_rate_lag_1', 'implicite_fund_...   \n",
       "1  LogisticRegression  ['implicite_fund_rate_lag_1', 'implicite_fund_...   \n",
       "2  LogisticRegression  ['implicite_fund_rate_lag_1', 'implicite_fund_...   \n",
       "3  LogisticRegression  ['implicite_fund_rate_lag_1', 'implicite_fund_...   \n",
       "4  LogisticRegression  ['implicite_fund_rate_lag_1', 'implicite_fund_...   \n",
       "\n",
       "                                 params.kwargs             tags.mlflow.runName  \n",
       "0          {'penalty': 'l1', 'solver': 'saga'}     lr-per-vars0.02-l1_FedFunds  \n",
       "1  {'penalty': 'elasticnet', 'solver': 'saga'}  lr-per-vars0.02-elnet_FedFunds  \n",
       "2  {'penalty': 'elasticnet', 'solver': 'saga'}  lr-per-vars0.01-elnet_FedFunds  \n",
       "3          {'penalty': None, 'solver': 'saga'}            lr-all-vars_FedFunds  \n",
       "4  {'penalty': 'elasticnet', 'solver': 'saga'}      lr-all-vars-elnet_FedFunds  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best=runs.sort_values(\"metrics.accuracy\",ascending=False)[[\"status\",\"run_id\",\"metrics.accuracy\",\"params.model_type\",\"params.variables\",\"params.kwargs\",\"tags.mlflow.runName\"]].reset_index(drop=True)\n",
    "champion_model_id=best[\"run_id\"][0]\n",
    "champion_model_variables=best[\"params.variables\"][0]\n",
    "best.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b0d44a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Downloading artifacts: 100%|██████████| 5/5 [00:00<00:00, 1055.91it/s] \n"
     ]
    }
   ],
   "source": [
    "champion_model=mlflow.pyfunc.load_model(f\"runs:/{champion_model_id}/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4ace5b73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['implicite_fund_rate_lag_1', 'implicite_fund_rate_lag_2', 'implicite_fund_rate_lag_4', 'implicite_fund_rate_lag_5', 'implicite_fund_rate_lag_6', 'PAYEMS_1', 'PAYEMS_4', 'GDP_2', 'INDPRO_1', 'FinStress_3']\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "champion_model_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728218ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "TO DO LIST::\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "do rolling training and plot curves\n",
    "\n",
    "do mlflow UI\n",
    "\n",
    "reassemble data in data folder, find ressources\n",
    "\n",
    "target is right? \n",
    "\n",
    "do clean notebook and folder structure \n",
    "\n",
    "push to main \n",
    "\n",
    "\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
